# ğŸš€ AI Showcase Platform - Replit Development Prompt

## ğŸ“‹ **Project Overview**
Táº¡o má»™t AI showcase platform hoÃ n chá»‰nh vá»›i multiple AI services, modern web interface, vÃ  production-ready architecture sá»­ dá»¥ng Replit environment.

## ğŸ¯ **Core Requirements**

### **Frontend - Next.js 15** 
- Framework: Next.js 15 vá»›i App Router 
- UI Library: Tailwind CSS + Shadcn/ui components
- State Management: Zustand hoáº·c React Context
- Styling: Modern glassmorphism design vá»›i dark theme
- Responsive: Mobile-first approach
- Animation: Framer Motion cho smooth transitions


### **Backend - FastAPI**
- Framework: FastAPI vá»›i async/await
- API Documentation: Automatic OpenAPI/Swagger
- Authentication: JWT-based auth (optional)
- File Upload: Multipart form handling
- CORS: Configured for frontend integration
- Error Handling: Comprehensive exception handling


### **AI Services Integration**

#### **1. Image Generation Service**
- Model: Stable Diffusion hoáº·c OpenAI DALL-E API
- Features: Text-to-image, style transfer, image editing
- Parameters: Resolution, style, steps, guidance scale

#### **2. Image Classification**
- Model: ResNet, EfficientNet, hoáº·c Vision Transformer
- Features: Multi-class classification, confidence scores
- Support: Popular datasets (ImageNet, CIFAR, custom)

#### **3. Object Detection**
- Model: YOLO v8, DETR, hoáº·c R-CNN
- Features: Bounding boxes, class labels, confidence
- Real-time: Webcam integration option

#### **4. Image Segmentation**
- Model: SAM, U-Net, hoáº·c DeepLab
- Features: Semantic/Instance segmentation
- Interactive: Click-to-segment functionality

#### **5. Chatbot Service**
- Model: OpenAI GPT, Llama, hoáº·c custom fine-tuned
- Features: Context-aware conversations, memory
- Integration: RAG vá»›i vector database (optional)

### **MLOps Stack**

#### **MLflow Integration**
python
# Requirements
- Experiment tracking cho táº¥t cáº£ models
- Model registry vá»›i versioning
- Metrics logging (accuracy, latency, throughput)
- Artifact storage cho model files
- Model deployment pipeline


#### **TorchServe Deployment**
python
# Model Serving
- Multi-model serving architecture  
- Custom handlers cho tá»«ng AI service
- Auto-scaling configuration
- Health checks vÃ  monitoring
- Batch inference support


### **Docker Configuration**
dockerfile
# Multi-stage build setup
- Base image: Python 3.11-slim
- Separate containers: Frontend, Backend, MLflow, TorchServe
- Docker Compose: Orchestration cho development
- Volume mounts: Model storage vÃ  logs
- Environment variables: Configuration management


## ğŸ—ï¸ **Project Structure**
ai-showcase/
â”œâ”€â”€ frontend/                 # Next.js application
â”‚   â”œâ”€â”€ app/
â”‚   â”‚   â”œâ”€â”€ (dashboard)/
â”‚   â”‚   â”‚   â”œâ”€â”€ generate/     # Image generation
â”‚   â”‚   â”‚   â”œâ”€â”€ classify/     # Classification
â”‚   â”‚   â”‚   â”œâ”€â”€ detect/       # Object detection  
â”‚   â”‚   â”‚   â”œâ”€â”€ segment/      # Segmentation
â”‚   â”‚   â”‚   â””â”€â”€ chat/         # Chatbot
â”‚   â”‚   â”œâ”€â”€ api/              # API routes
â”‚   â”‚   â””â”€â”€ components/       # Reusable components
â”‚   â”œâ”€â”€ lib/                  # Utilities & configs
â”‚   â””â”€â”€ public/               # Static assets
â”œâ”€â”€ backend/                  # FastAPI application
â”‚   â”œâ”€â”€ app/
â”‚   â”‚   â”œâ”€â”€ api/
â”‚   â”‚   â”‚   â”œâ”€â”€ v1/
â”‚   â”‚   â”‚   â”‚   â”œâ”€â”€ generate.py
â”‚   â”‚   â”‚   â”‚   â”œâ”€â”€ classify.py
â”‚   â”‚   â”‚   â”‚   â”œâ”€â”€ detect.py
â”‚   â”‚   â”‚   â”‚   â”œâ”€â”€ segment.py
â”‚   â”‚   â”‚   â”‚   â””â”€â”€ chat.py
â”‚   â”‚   â”œâ”€â”€ core/             # Configuration
â”‚   â”‚   â”œâ”€â”€ models/           # Pydantic models
â”‚   â”‚   â”œâ”€â”€ services/         # Business logic
â”‚   â”‚   â””â”€â”€ utils/            # Helper functions
â”‚   â””â”€â”€ requirements.txt
â”œâ”€â”€ models/                   # AI models & handlers
â”‚   â”œâ”€â”€ torchserve/
â”‚   â”‚   â”œâ”€â”€ handlers/
â”‚   â”‚   â”œâ”€â”€ config/
â”‚   â”‚   â””â”€â”€ model_store/
â”‚   â””â”€â”€ mlflow/
â”‚       â”œâ”€â”€ experiments/
â”‚       â””â”€â”€ models/
â”œâ”€â”€ docker/
â”‚   â”œâ”€â”€ Dockerfile.frontend
â”‚   â”œâ”€â”€ Dockerfile.backend
â”‚   â”œâ”€â”€ Dockerfile.torchserve
â”‚   â””â”€â”€ docker-compose.yml
â””â”€â”€ README.md


## ğŸ’» **Implementation Steps**

### **Step 1: Environment Setup**
bash
# Replit configuration
- Python 3.11+ environment
- Node.js 18+ for Next.js
- Poetry hoáº·c pip cho dependency management
- Environment variables setup


### **Step 2: Backend Development**
python
# FastAPI application vá»›i endpoints:
@app.post("/api/v1/generate")     # Image generation
@app.post("/api/v1/classify")     # Image classification  
@app.post("/api/v1/detect")       # Object detection
@app.post("/api/v1/segment")      # Image segmentation
@app.post("/api/v1/chat")         # Chatbot conversation

# MLflow integration
- Initialize tracking server
- Log experiments automatically
- Model registration pipeline


### **Step 3: AI Models Integration**
python
# TorchServe handlers cho má»—i service
class ImageGenerationHandler:
    def preprocess(self, data):
        # Text prompt processing
    
    def inference(self, data):
        # Model inference
        
    def postprocess(self, data):
        # Image output formatting

# TÆ°Æ¡ng tá»± cho cÃ¡c services khÃ¡c


### **Step 4: Frontend Development**
tsx
// Next.js components vá»›i modern UI
interface AIService {
  id: string;
  name: string;
  description: string;
  endpoint: string;
  inputType: 'text' | 'image' | 'both';
  outputType: 'image' | 'json' | 'text';
}

// Dashboard vá»›i service cards
// Upload components vá»›i drag-and-drop
// Results display vá»›i loading states
// Real-time processing indicators


### **Step 5: Docker Configuration**
dockerfile
# Multi-service setup
- Frontend container (Next.js)
- Backend container (FastAPI)
- TorchServe container
- MLflow tracking server
- Database (PostgreSQL/SQLite)


## ğŸ¨ **UI/UX Features**

### **Dashboard Layout**
- Modern sidebar navigation
- Service cards vá»›i preview
- Progress indicators
- Result galleries
- Performance metrics

### **Interactive Elements**
- Drag-and-drop file upload
- Real-time processing status
- Parameter sliders/controls
- Before/after comparisons
- Download results functionality

### **Responsive Design**
- Mobile-optimized interface
- Touch-friendly controls
- Adaptive layouts
- Progressive loading

## ğŸ“Š **Monitoring & Analytics**

### **MLflow Tracking**
python
# Metrics tracking cho má»—i request
- Processing latency
- Model accuracy/confidence
- Resource utilization
- Error rates
- User engagement


### **Performance Monitoring**
- Request/response times
- Model inference speed
- Memory usage
- GPU utilization (if available)
- API endpoint analytics

## ğŸ”§ **Advanced Features**

### **Batch Processing**
- Multiple file upload
- Queue management
- Progress tracking
- Result aggregation

### **Model Management**
- A/B testing framework
- Model versioning
- Rollback capabilities
- Performance comparison

### **User Experience**
- Processing history
- Favorite results
- Share functionality
- Export options

## ğŸš€ **Deployment Instructions**

### **Replit Deployment**
bash
# 1. Create new Replit project
# 2. Upload project structure
# 3. Configure environment variables
# 4. Set up port forwarding
# 5. Initialize services

# Run commands:
pip install -r backend/requirements.txt
npm install --prefix frontend
python -m uvicorn backend.app.main:app --host 0.0.0.0 --port 8000
npm run dev --prefix frontend


### **Production Considerations**
- Load balancing cho multiple models
- Caching strategies
- Rate limiting
- Security headers
- SSL certificates

## ğŸ“ **Example Implementation**

HÃ£y táº¡o má»™t prototype Ä‘áº§y Ä‘á»§ vá»›i:
- 5 AI services hoáº¡t Ä‘á»™ng
- Modern Next.js frontend
- FastAPI backend vá»›i MLflow
- Docker containerization
- Comprehensive documentation
- Demo data vÃ  examples

## ğŸ¯ **Success Criteria**
- âœ… All AI services functional
- âœ… Modern, responsive UI
- âœ… MLflow experiment tracking
- âœ… TorchServe model serving
- âœ… Docker deployment ready
- âœ… Production-quality code
- âœ… Comprehensive documentation

---